{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651cfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10, FashionMNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0273065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13 (main, Aug 25 2022, 23:26:10) \n",
      "[GCC 11.2.0]\n",
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, random, time, copy, scipy, pickle, sys, math\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "import scipy.io as sio\n",
    "from scipy import misc\n",
    "from scipy import ndimage, signal\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "from skimage import data, img_as_float\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import sklearn.metrics \n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from utils.eval_funcs import *\n",
    "from utils.dataset_CIFAR100LT import *\n",
    "from utils.network_arch_resnet import *\n",
    "from utils.trainval import *\n",
    "from utils.plot_funcs import *\n",
    "import warnings # ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(sys.version)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe04dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义深度卷积神经网络模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            #nn.Linear(64 * 16 * 16, 128),\n",
    "            nn.Linear(64 * 16 * 16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            #nn.Linear(64 * 16 * 16, 128),\n",
    "            nn.Linear(64 * 14 * 14, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.unknown_class = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def open_set_forward(self, x, known_classes):\n",
    "        x = self.features(x)\n",
    "        #print(x.shape) \n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape) \n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        # 计算每个样本的开放集得分\n",
    "        open_scores = torch.softmax(logits[:, known_classes], dim=1)\n",
    "\n",
    "        # 添加未知类别得分\n",
    "        unknown_scores = torch.zeros(x.size(0), 1).to(x.device)\n",
    "        open_scores = torch.cat((open_scores, unknown_scores), dim=1)\n",
    "\n",
    "        return open_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c42329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子和设备\n",
    "torch.manual_seed(2024)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f05d3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_number=[]\n",
    "loss_record=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513a259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number=[]\n",
    "class_acc=[]\n",
    "class_sample=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89cf340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练闭集模型\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_number.append(epoch)\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        loss_record.append(running_loss / len(train_loader))\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1dfdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试开放集识别\n",
    "def test(model, test_loader, known_classes):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            open_scores = model.open_set_forward(images, known_classes)\n",
    "            _, predicted = torch.max(open_scores.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5abaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntransform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Resize((32, 32)),\\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据预处理和加载器\n",
    "'''\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6f27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the transformations for CIFAR10\n",
    "transform_cifar = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948a3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for MNIST\n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a22eb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_dataset = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transform_cifar)\\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transform_cifar)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bbfec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 加载CIFAR10测试集\n",
    "testset = torchvision.datasets.CIFAR10(root='data', train=False,\n",
    "                                       download=True, transform=transform_cifar)\n",
    "testloader = DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca57aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.FashionMNIST(root='data', train=False, download=True, transform=transform_mnist)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c54f71b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Class 0: 250000 samples\n",
      "Class 1: 234500 samples\n",
      "Class 2: 220500 samples\n",
      "Class 3: 207000 samples\n",
      "Class 4: 194000 samples\n",
      "Class 5: 182500 samples\n",
      "Class 6: 171500 samples\n",
      "Class 7: 161000 samples\n",
      "Class 8: 151000 samples\n",
      "Class 9: 142000 samples\n",
      "Class 10: 133000 samples\n",
      "Class 11: 125000 samples\n",
      "Class 12: 117500 samples\n",
      "Class 13: 110500 samples\n",
      "Class 14: 103500 samples\n",
      "Class 15: 97500 samples\n",
      "Class 16: 91500 samples\n",
      "Class 17: 85500 samples\n",
      "Class 18: 80500 samples\n",
      "Class 19: 75500 samples\n",
      "Class 20: 71000 samples\n",
      "Class 21: 66500 samples\n",
      "Class 22: 62500 samples\n",
      "Class 23: 59000 samples\n",
      "Class 24: 55000 samples\n",
      "Class 25: 52000 samples\n",
      "Class 26: 48500 samples\n",
      "Class 27: 45500 samples\n",
      "Class 28: 43000 samples\n",
      "Class 29: 40000 samples\n",
      "Class 30: 38000 samples\n",
      "Class 31: 35500 samples\n",
      "Class 32: 33500 samples\n",
      "Class 33: 31000 samples\n",
      "Class 34: 29500 samples\n",
      "Class 35: 27500 samples\n",
      "Class 36: 26000 samples\n",
      "Class 37: 24500 samples\n",
      "Class 38: 23000 samples\n",
      "Class 39: 21500 samples\n",
      "Class 40: 20000 samples\n",
      "Class 41: 19000 samples\n",
      "Class 42: 17500 samples\n",
      "Class 43: 16500 samples\n",
      "Class 44: 15500 samples\n",
      "Class 45: 14500 samples\n",
      "Class 46: 13500 samples\n",
      "Class 47: 13000 samples\n",
      "Class 48: 12000 samples\n",
      "Class 49: 11500 samples\n",
      "Class 50: 10500 samples\n",
      "Class 51: 10000 samples\n",
      "Class 52: 9500 samples\n",
      "Class 53: 8500 samples\n",
      "Class 54: 8000 samples\n",
      "Class 55: 7500 samples\n",
      "Class 56: 7000 samples\n",
      "Class 57: 6500 samples\n",
      "Class 58: 6500 samples\n",
      "Class 59: 6000 samples\n",
      "Class 60: 5500 samples\n",
      "Class 61: 5000 samples\n",
      "Class 62: 5000 samples\n",
      "Class 63: 4500 samples\n",
      "Class 64: 4000 samples\n",
      "Class 65: 4000 samples\n",
      "Class 66: 3500 samples\n",
      "Class 67: 3500 samples\n",
      "Class 68: 3500 samples\n",
      "Class 69: 3000 samples\n",
      "Class 70: 3000 samples\n",
      "Class 71: 2500 samples\n",
      "Class 72: 2500 samples\n",
      "Class 73: 2500 samples\n",
      "Class 74: 2000 samples\n",
      "Class 75: 2000 samples\n",
      "Class 76: 2000 samples\n",
      "Class 77: 1500 samples\n",
      "Class 78: 1500 samples\n",
      "Class 79: 1500 samples\n",
      "Class 80: 1500 samples\n",
      "Class 81: 1500 samples\n",
      "Class 82: 1000 samples\n",
      "Class 83: 1000 samples\n",
      "Class 84: 1000 samples\n",
      "Class 85: 1000 samples\n",
      "Class 86: 1000 samples\n",
      "Class 87: 1000 samples\n",
      "Class 88: 500 samples\n",
      "Class 89: 500 samples\n",
      "Class 90: 500 samples\n",
      "Class 91: 500 samples\n",
      "Class 92: 500 samples\n",
      "Class 93: 500 samples\n",
      "Class 94: 500 samples\n",
      "Class 95: 500 samples\n",
      "Class 96: 500 samples\n",
      "Class 97: 500 samples\n",
      "Class 98: 500 samples\n",
      "Class 99: 500 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "\n",
    "def build_long_tailed_dataset(dataset, imbalance_ratio):\n",
    "    num_classes = len(dataset.classes)\n",
    "    class_counts = np.zeros(num_classes, dtype=int)\n",
    "    \n",
    "    for _, label in dataset:\n",
    "        class_counts[label] += 1\n",
    "    \n",
    "    max_class_count = class_counts.max()\n",
    "    \n",
    "    # Calculate the number of samples to keep for each class based on the imbalance ratio\n",
    "    #num_samples_per_class = np.zeros(num_classes, dtype=int)\n",
    "    total_num=50000\n",
    "    imb_type = 'exp' # samling long-tailed training set with an exponetially-decaying function\n",
    "    imb_factor = 0.002 # imbalance factor = 100 = 1/0.01\n",
    "    num_samples_per_class = get_img_num_per_cls(100, total_num, imb_type, imb_factor)\n",
    "    #for i, count in enumerate(class_counts):\n",
    "        #num_samples_per_class[i] = int(max_class_count / (imbalance_ratio ** i))\n",
    "        #num_samples_per_class[i] = int(max_class_count -imbalance_ratio **i)\n",
    "    \n",
    "    # Create a new dataset with imbalanced class distribution\n",
    "    long_tailed_dataset = []\n",
    "    \n",
    "    for data, label in dataset:\n",
    "        class_count = class_counts[label]\n",
    "        num_samples = num_samples_per_class[label]\n",
    "        \n",
    "        if class_count <= num_samples:\n",
    "            long_tailed_dataset.extend([(data, label)] * class_count)\n",
    "        else:\n",
    "            long_tailed_dataset.extend([(data, label)] * num_samples)\n",
    "    \n",
    "    return long_tailed_dataset\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "cifar100_train = datasets.CIFAR100(root='data', train=True, download=True, transform=transform_cifar)\n",
    "\n",
    "# Build a long-tailed version of the CIFAR-100 dataset with imbalance ratio of 10\n",
    "imbalance_ratio = 1.06\n",
    "\n",
    "long_tailed_cifar100_train = build_long_tailed_dataset(cifar100_train, imbalance_ratio)\n",
    "\n",
    "# Print the class distribution of the long-tailed dataset\n",
    "class_counts = np.zeros(100, dtype=int)\n",
    "for _, label in long_tailed_cifar100_train:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"Class {i}: {count} samples\")\n",
    "    class_sample.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2ca6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(long_tailed_cifar100_train, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5696d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar100_test = datasets.CIFAR100(root='data', train=False, download=True, transform=transform_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "370f6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader=DataLoader(cifar100_test, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c45c0f1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92236/1808480290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model = models.resnet18(nClasses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
     ]
    }
   ],
   "source": [
    "# 初始化模型、损失函数和优化器\n",
    "num_classes = 100  # 已知类别数量\n",
    "model = Model(num_classes)\n",
    "#model = models.resnet18(nClasses)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ed646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = [0] * 100\n",
    "class_total = [0] * 100\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(100):\n",
    "    class_number.append(i)\n",
    "    accuracy = 100 * class_correct[i] / class_total[i]\n",
    "    class_acc.append(accuracy)\n",
    "    print(f'Accuracy of class {i}: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86acae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('class')\n",
    "plt.ylabel('samples')\n",
    "plt.title(\"The change of samples under different classess\")\n",
    "plt.plot(class_number, class_sample, linewidth=2,  marker='.')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb48653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "#test(model, test_loader, known_classes=list(range(num_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "'''\n",
    "# 计算开放集似然性\n",
    "def calculate_open_set_likelihood(testloader, open_set_loader):\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    scores = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, true_labels = data\n",
    "            images = images.to(device)\n",
    "            true_labels = true_labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probabilities = softmax(outputs)\n",
    "            max_probabilities, _ = torch.max(probabilities, 1)\n",
    "            scores.extend(max_probabilities.cpu().numpy())\n",
    "            labels.extend(true_labels.cpu().numpy())\n",
    "\n",
    "    open_set_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in open_set_loader:\n",
    "            images, _ = data\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probabilities = softmax(outputs)\n",
    "            max_probabilities, _ = torch.max(probabilities, 1)\n",
    "            open_set_scores.extend(max_probabilities.cpu().numpy())\n",
    "\n",
    "    return np.array(scores), np.array(open_set_scores), np.array(labels)\n",
    "\n",
    "# 计算似然性并绘制ROC曲线\n",
    "scores, open_set_scores, labels = calculate_open_set_likelihood(testloader, test_loader)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "open_set_fpr, open_set_tpr, _ = roc_curve(np.concatenate((np.ones_like(labels), np.zeros_like(open_set_scores))), np.concatenate((scores, open_set_scores)))\n",
    "open_set_roc_auc = auc(open_set_fpr, open_set_tpr)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot(open_set_fpr, open_set_tpr, color='blue', linestyle='--', label='Open-set ROC curve (area = %0.2f)' % open_set_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9fa6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title(\"The change of loss under different epoches\")\n",
    "plt.plot(epoch_number, loss_record, linewidth=2,  marker='.')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('class')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"The change of accuracy under different classess\")\n",
    "#plt.plot(class_number, class_acc, linewidth=2,  marker='.')\n",
    "plt.bar(class_number, class_acc)\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584905c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
